{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection = cv.CascadeClassifier(\"harrcascade_face_detection_classifier.xml\")\n",
    "def generate_dataset():\n",
    "    \n",
    "    def image_crop(img):\n",
    "        gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        faces = face_detection.detectMultiScale(gray,scaleFactor=1.4,minNeighbors=5)\n",
    "        \n",
    "        if faces is ():\n",
    "            return None\n",
    "        for(x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    \n",
    "    capture = cv.VideoCapture(0)\n",
    "    img_id = 0\n",
    "    while True:\n",
    "        isFrameRead,frame = capture.read()\n",
    "        if image_crop(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv.resize(image_crop(frame),(250,250))\n",
    "            face = cv.cvtColor(face,cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "\n",
    "            # To generate dataset (Training ot Testing) uncomment respective lines.\n",
    "\n",
    "            # For Validate dataset\n",
    "            # Generate Dataset for Testing\n",
    "            # path = \"Visualize/\"+str(img_id)+\".jpg\"\n",
    "\n",
    "\n",
    "            # Generate Dataset\n",
    "            # Generate Dataset for Training \n",
    "            # path = \"Data/\"+\"Name of person.\"+str(img_id)+\".jpg\"\n",
    "\n",
    "            cv.imwrite(path,face)\n",
    "            cv.putText(face,str(img_id),(50,50),cv.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            \n",
    "            cv.imshow(\"Face\",face)\n",
    "            # change image id and number of images to generate accordingly.\n",
    "            # prefer : use 20 images for testing and 1000 images for training  \n",
    "\n",
    "            if cv.waitKey(1)==13 or int(img_id)==1000: # number of images \n",
    "                break\n",
    "    capture.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(\"Data Collected Successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(img_name):\n",
    "    name = img_name.split('.')[-3]\n",
    "    if not img_name.endswith('.jpg'):\n",
    "        return None\n",
    "    if name == \"Name of Person1\":\n",
    "        return np.array([1,0,0,0])\n",
    "    elif name == \"Name of Person2\":\n",
    "        return np.array([0,1,0,0])\n",
    "    elif name == \"Name of Person3\":   \n",
    "        return np.array([0,0,1,0])\n",
    "    elif name==\"Name of Person4\":\n",
    "        return np.array([0,0,0,1])\n",
    "\n",
    "\n",
    "# You can add more number of peoples as present in Training dataset and cahange the array accordingly.\n",
    "# If there are 2 persons the array is like [1,0] and [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    data = []\n",
    "    for img in tqdm(os.listdir(\"Data\")):\n",
    "        path = os.path.join(\"Data\",img)\n",
    "        img_data = cv.imread(path,cv.IMREAD_GRAYSCALE)\n",
    "        img_data = cv.resize(img_data,(50,50))\n",
    "        data.append([np.array(img_data),generate_label(img)])\n",
    "        \n",
    "    shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data,testing_data = train_test_split(data,test_size=0.3,random_state=25)\n",
    "\n",
    "train_data = np.array([i[0] for i in training_data]).reshape(-1,50,50,1)\n",
    "train_label = [i[1] for i in training_data]\n",
    "\n",
    "test_data = np.array([i[0] for i in testing_data]).reshape(-1,50,50,1)\n",
    "test_label = [i[1] for i in testing_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d,max_pool_2d\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "convent = input_data(shape=[50, 50, 1])\n",
    "convent = conv_2d(convent,32,5,activation='relu')\n",
    "convent = max_pool_2d(convent,5)\n",
    "convent = conv_2d(convent,64,5,activation='relu')\n",
    "convent = max_pool_2d(convent,5)\n",
    "convent = conv_2d(convent,128,1,activation='relu')\n",
    "convent = max_pool_2d(convent,1)\n",
    "convent = conv_2d(convent,64,1,activation='relu')\n",
    "convent = max_pool_2d(convent,1)\n",
    "convent = conv_2d(convent,32,1,activation='relu')\n",
    "convent = max_pool_2d(convent,1)\n",
    "\n",
    "convent = fully_connected(convent,1024,activation='relu')\n",
    "convent = dropout(convent,0.8)\n",
    "\n",
    "# to change no of users \n",
    "# change 4 to number of persons present in Training Dataset accordingly.\n",
    "convent = fully_connected(convent,4,activation='softmax')\n",
    "convent = regression(convent,optimizer='adam',learning_rate=0.001,loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(convent,tensorboard_verbose=1)  \n",
    "history = model.fit(train_data,train_label,n_epoch=11,validation_set=(test_data,test_label),show_metric=True,run_id=\"frs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_visualize():\n",
    "    vdata=[]\n",
    "    for img in tqdm(os.listdir(\"Visualize\")):\n",
    "        path = os.path.join(\"Visualize\",img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img_data = cv.imread(path,cv.IMREAD_GRAYSCALE)\n",
    "        img_data = cv.resize(img_data,(50,50))\n",
    "        vdata.append([np.array(img_data),img_num])\n",
    "    shuffle(vdata)\n",
    "    return vdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Vdata = data_for_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for num ,data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5,num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(-1,50,50,1)\n",
    "    model_out = model.predict([data][0])\n",
    "    # add according to data\n",
    " \n",
    "    if np.argmax(model_out) == 0:\n",
    "        my_label=\"Name of Person1\"\n",
    "    elif np.argmax(model_out) == 1 :\n",
    "        my_label=\"Name of Person2\"\n",
    "    elif np.argmax(model_out) ==2:    \n",
    "        my_label=\"Name of Person3\"\n",
    "    elif np.argmax(model_out)==3:\n",
    "        my_label=\"Name of Person4\"\n",
    "   \n",
    "\n",
    "    y.imshow(image,cmap='gray')\n",
    "    plt.title(my_label)\n",
    "\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
